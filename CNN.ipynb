{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import gzip\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Current device: NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "# Check CUDA availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"Current device: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_vectors():\n",
    "\n",
    "    filename = \"GoogleNews-vectors-negative300.bin.gz\"\n",
    "    url = f\"https://github.com/aburkov/theLLMbook/releases/download/v1.0.0/{filename}\"\n",
    "\n",
    "    with tqdm(unit='B', unit_scale=True, unit_divisor=1024, miniters=1, desc=filename) as progress_bar:\n",
    "        def report_hook(count, block_size, total_size):\n",
    "            if total_size != -1:\n",
    "                progress_bar.total = total_size\n",
    "            progress_bar.update(block_size)\n",
    "\n",
    "        urllib.request.urlretrieve(url, filename, reporthook=report_hook)\n",
    "\n",
    "    with gzip.open(filename, 'rb') as f:\n",
    "        header = f.readline()\n",
    "        vocab_size, vector_size = map(int, header.split())\n",
    "\n",
    "        vectors = {}\n",
    "        binary_len = np.dtype('float32').itemsize * vector_size\n",
    "\n",
    "        with tqdm(total=vocab_size, desc=\"Loading word vectors\") as pbar:\n",
    "            for _ in range(vocab_size):\n",
    "                word = []\n",
    "                while True:\n",
    "                    ch = f.read(1)\n",
    "                    if ch == b' ':\n",
    "                        word = b''.join(word).decode('utf-8')\n",
    "                        break\n",
    "                    if ch != b'\\n':\n",
    "                        word.append(ch)\n",
    "\n",
    "                vector = np.frombuffer(f.read(binary_len), dtype='float32')\n",
    "                if re.search(r\"^[a-z]+$\", word):\n",
    "                    vectors[word] = vector\n",
    "                pbar.update(1)\n",
    "\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text(text, word_vectors, max_length=5000):\n",
    "    words = text.lower().split()[:max_length]\n",
    "    embeddings = [word_vectors.get(word, np.zeros(300)) for word in words]\n",
    "    padding = [np.zeros(300)] * (max_length - len(embeddings))\n",
    "    return np.array(embeddings + padding)[:max_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewsGroupDataset(Dataset):\n",
    "    def __init__(self, texts, labels, word_vectors, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.word_vectors = word_vectors\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        embeddings = embed_text(self.texts[idx], self.word_vectors, max_len)\n",
    "        return torch.tensor(embeddings, dtype=torch.float32), torch.tensor(self.labels[idx], dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_classes, max_len):\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(embedding_dim, 512, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv1d(512, 512, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv1d(512, 64, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.fc = nn.Linear(64 * (max_len // 8), num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GoogleNews-vectors-negative300.bin.gz: 1.53GB [00:21, 75.3MB/s]                               \n",
      "Loading word vectors: 100%|██████████| 3000000/3000000 [00:28<00:00, 104292.78it/s]\n"
     ]
    }
   ],
   "source": [
    "word_vectors = load_word_vectors()\n",
    "newsgroups = fetch_20newsgroups(remove=(\"headers\", \"footers\", \"quotes\"))\n",
    "X = newsgroups.data\n",
    "y = newsgroups.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\\\n",
    "                test_size=0.2, random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "max_len = 500\n",
    "train_dataset = NewsGroupDataset(X_train, y_train, word_vectors, max_len)\n",
    "test_dataset = NewsGroupDataset(X_test, y_test, word_vectors, max_len)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = TextCNN(300, 20, max_len)\n",
    "model = model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Train Accuracy: 11.58%, Test Accuracy: 16.17%\n",
      "Epoch [2/20], Train Accuracy: 25.94%, Test Accuracy: 32.52%\n",
      "Epoch [3/20], Train Accuracy: 38.61%, Test Accuracy: 40.21%\n",
      "Epoch [4/20], Train Accuracy: 44.93%, Test Accuracy: 46.00%\n",
      "Epoch [5/20], Train Accuracy: 50.72%, Test Accuracy: 50.68%\n",
      "Epoch [6/20], Train Accuracy: 57.28%, Test Accuracy: 52.45%\n",
      "Epoch [7/20], Train Accuracy: 60.47%, Test Accuracy: 55.02%\n",
      "Epoch [8/20], Train Accuracy: 63.57%, Test Accuracy: 56.61%\n",
      "Epoch [9/20], Train Accuracy: 66.77%, Test Accuracy: 56.16%\n",
      "Epoch [10/20], Train Accuracy: 69.02%, Test Accuracy: 56.56%\n",
      "Epoch [11/20], Train Accuracy: 70.69%, Test Accuracy: 56.39%\n",
      "Epoch [12/20], Train Accuracy: 73.34%, Test Accuracy: 57.71%\n",
      "Epoch [13/20], Train Accuracy: 73.93%, Test Accuracy: 57.98%\n",
      "Epoch [14/20], Train Accuracy: 75.86%, Test Accuracy: 58.37%\n",
      "Epoch [15/20], Train Accuracy: 76.63%, Test Accuracy: 57.58%\n",
      "Epoch [16/20], Train Accuracy: 77.72%, Test Accuracy: 57.80%\n",
      "Epoch [17/20], Train Accuracy: 79.09%, Test Accuracy: 58.95%\n",
      "Epoch [18/20], Train Accuracy: 79.95%, Test Accuracy: 58.90%\n",
      "Epoch [19/20], Train Accuracy: 79.94%, Test Accuracy: 58.95%\n",
      "Epoch [20/20], Train Accuracy: 80.54%, Test Accuracy: 57.80%\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    for batch_embeddings, batch_labels in train_loader:\n",
    "        batch_embeddings, batch_labels = batch_embeddings.to(device), batch_labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_embeddings)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += batch_labels.size(0)\n",
    "        train_correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_embeddings, batch_labels in test_loader:\n",
    "            batch_embeddings, batch_labels = batch_embeddings.to(device), batch_labels.to(device)\n",
    "            outputs = model(batch_embeddings)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            test_total += batch_labels.size(0)\n",
    "            test_correct += (predicted == batch_labels).sum().item()\n",
    "\n",
    "    test_accuracy = 100 * test_correct / test_total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Accuracy: {train_accuracy:.2f}%, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llmbook",
   "language": "python",
   "name": ".llmbook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
